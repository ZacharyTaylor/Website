---
- !ruby/object:Paper
  title: Parameterless Automatic Extrinsic Calibration of Vehicle Mounted Lidar-Camera Systems
  conference: ICRA 2014 LTA Workshop
  abstract: This paper presents a new method for automated extrinsic calibration of multi-modal sensors. In particular the paper presents and evaluates a pipeline for calibration of 3D lidar and cameras mounted on a sensor vehicle. Previous methods for multi-modal sensor calibration find the optimal parameters by aligning a set of observations from the different sensor modalities. The main drawback of these methods is the need for a good initialisation in order to avoid converging into a local minima. Our approach eliminates this limitation by combining external observations with motion estimates obtained with the individual sensors. The method operates by utilizing structure from motion based hand-eye calibration to constrain the search space of the optimisation.
  file: ICRA2014_LTA.pdf
  image: ICRA2014_LTA.jpg
- !ruby/object:Paper
  title: Multi-modal sensor calibration using a gradient orientation measure
  conference: JFR
  abstract: This paper presents a new metric for automated registration of multi-modal sensor data. The metric is based on the alignment of the orientation of gradients formed from the two candidate sensors. Data registration is performed by estimating the sensorsâ€™ extrinsic parameters that minimises the misalignment of the gradients. The metric can operate in a large range of applications working on both 2D and 3D sensor outputs and is suitable for both (i) single scan data registration and (ii) multi-sensor platform calibration using multiple scans. Unlike traditional calibration methods, it does not require markers or other registration aids to be placed in the scene. The effectiveness of the new method is demonstrated with experimental results on a variety of camera-lidar and camera-camera calibration problems. The novel metric is validated through comparisons with state of the art methods. Our approach is shown to give high quality registrations under all tested conditions.
  file: JFR2013.pdf
  image: JFR2013.jpg
- !ruby/object:Paper
  title: Automatic Calibration of Multi-Modal Sensor Systems using a Gradient Orientation Measure
  conference: IROS 2013
  abstract: A novel technique for calibrating a multi-modal sensor system has been developed. Our calibration method is based on the comparative alignment of output gradients from two candidate sensors. The algorithm is applied to the calibration of the extrinsic parameters of several camera-lidar systems. In this calibration the lidar scan is projected onto the camera's image using a camera model. Particle swarm optimization is used to find the optimal parameters for this model. This method requires no markers to be placed in the scene. While the system can use a set of scans, unlike many existing techniques it can also automatically calibrate the system reliably using a single scan. The method presented is successfully validated on a variety of cameras, lidars and locations. It is also compared to three existing techniques and shown to give comparable or superior results on the datasets tested.
  file: IROS2013.pdf
  image: IROS2013.jpg
- !ruby/object:Paper
  title: Orchard Fruit Segmentation using Multi-spectral Feature Learning
  conference: IROS 2013
  abstract: This paper presents a multi-class image segmentation approach to automate fruit segmentation. A feature learning algorithm combined with a conditional random field is applied to multi-spectral image data. Current classification methods used in agriculture scenarios tend to use hand crafted application-based features. In contrast, our approach uses unsupervised feature learning to automatically capture most relevant features from the data. This property makes our approach robust against variance in canopy trees and therefore has the potential to be applied to different domains. The proposed algorithm is applied to a fruit segmentation problem for a robotic agricultural surveillance mission, aiming to provide yield estimation with high accuracy and robustness against fruit variance. Experimental results with data collected in an almond farm are shown. The segmentation is performed with features extracted from multi-spectral (colour and infrared) data. We achieve a global classification accuracy of 88%.
  file: IROS2013_2.jpg
  image: IROS2013_2.jpg
- !ruby/object:Paper
  title: A Mutual Information Approach to Automatic Calibration of Camera and Lidar in Natural Environments
  conference: ACRA 2012
  abstract: This paper presents a method for calibrating the extrinsic and intrinsic parameters of a camera and a lidar scanner. The approach uses normalised mutual information to compare an image with a lidar scan. A camera model that takes into account orientation, location and focal length is used to create a 2D lidar image, with the intensity of the pixels defined by the angle of the normals in the lidar scan. Particle swarm optimisation is used to find the optimal model parameters. The method is successfully validated in a natural environment with images collected by a hyperspectral and a 3D lidar scanner.
  file: ACRA2012.pdf
  image: ACRA2012.jpg
- !ruby/object:Paper
  title: Automatic Calibration of Lidar with Camera Images using Normalized Mutual Information
  conference: Internal 2012
  abstract: This paper is about automatic calibration of a camera-lidar system. The method presented is designed to be as general as possible allowing it to be used in a large range of systems and applications. The approach uses normalized mutual information to compare the cameras image with an image generated by a lidar scan of the same area. A camera model that takes into account orientation, location and focal length is used to create the lidar image, with the intensity of the pixels in the image representing a feature of the lidar scan that is chosen depending on the application. Particle swarm optimization is used to find the optimal model parameters. The method presented is successfully validated on a variety of cameras, lidars and locations, including scans of both urban and natural environments.
  file: Internal2012.pdf
  image: Internal2012.jpg
